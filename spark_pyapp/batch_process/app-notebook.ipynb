{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sys import argv\n",
    "\n",
    "from helpers.config import config\n",
    "from helpers.ioutil import download_data, put_file_in_hdfs\n",
    "from helpers.sparkutil import SparkUtil\n",
    "from constants.module_constants import ModuleConstants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://localhost:9000/data_1586586931606.csv\n"
     ]
    }
   ],
   "source": [
    "local_path = 'data_notebook.csv'\n",
    "download_data('https://chronicdata.cdc.gov/views/735e-byxc/rows.csv?accessType=DOWNLOAD', local_path)\n",
    "hdfs_file_path = config()['FILE'][ModuleConstants.HADOOP_FILE_COPY_PATH] + 'data_' +\\\n",
    "                 str(int(round(time.time() * 1000))) + '.csv'\n",
    "print(hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running shell command: hdfs dfs -put data_notebook.csv hdfs://localhost:9000/data_1586586931606.csv\n",
      "0 b'' b''\n"
     ]
    }
   ],
   "source": [
    "put_file_in_hdfs(local_path, hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_frame = SparkUtil.load_data(\"com.databricks.spark.csv\", hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, YearStart: string, YearEnd: string, LocationAbbr: string, LocationDesc: string, Datasource: string, Class: string, Topic: string, Question: string, Data_Value_Unit: string, Data_Value_Type: string, Data_Value: string, Data_Value_Alt: string, Data_Value_Footnote_Symbol: string, Data_Value_Footnote: string, Low_Confidence_Limit: string, High_Confidence_Limit: string, Sample_Size: string, Total: string, Age: string, Gender: string, Race/Ethnicity: string, GeoLocation: string, ClassID: string, TopicID: string, QuestionID: string, DataValueTypeID: string, LocationID: string, StratificationCategory1: string, Stratification1: string, StratificationCategoryId1: string, StratificationID1: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data_frame = batch_data_frame \\\n",
    "    .withColumnRenamed(\"High_Confidence_Limit \", \"High_Confidence_Limit\") \\\n",
    "    .withColumnRenamed(\"Age(months)\", \"Age\")\n",
    "batch_data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_frame.write.mode(\"overwrite\").saveAsTable(config()['HIVE'][ModuleConstants.HIVE_APP_TABLE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    9180|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'select count(*) from ' + config()['HIVE'][ModuleConstants.HIVE_APP_TABLE]\n",
    "SparkUtil.execute_show_query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query :: select 'ALL' AS category,questionid,yearstart AS year,avg(data_value) AS avarage from servay2020 group by questionid,yearstart order by questionid,yearstart  , storing results in :: servay_analysis_all_results\n",
      "+--------+----------+----+------------------+\n",
      "|category|questionid|year|           avarage|\n",
      "+--------+----------+----+------------------+\n",
      "|     ALL|      Q040|2008| 16.37172413793103|\n",
      "|     ALL|      Q040|2010|16.231841652323595|\n",
      "|     ALL|      Q040|2012|15.599483648881238|\n",
      "|     ALL|      Q040|2014|15.436269430051802|\n",
      "|     ALL|      Q040|2016|15.148615916955029|\n",
      "|     ALL|      Q041|2008|14.983793103448296|\n",
      "|     ALL|      Q041|2010|15.064716006884682|\n",
      "|     ALL|      Q041|2012|14.276592082616187|\n",
      "|     ALL|      Q041|2014|13.943350604490504|\n",
      "|     ALL|      Q041|2016| 13.53235294117647|\n",
      "|     ALL|      Q060|2008|13.218181818181813|\n",
      "|     ALL|      Q060|2010|13.046984126984121|\n",
      "|     ALL|      Q060|2012|11.963057324840753|\n",
      "|     ALL|      Q060|2014|11.450638977635784|\n",
      "|     ALL|      Q060|2016|11.577635782747599|\n",
      "+--------+----------+----+------------------+\n",
      "\n",
      "running query :: select 'FEMALE' AS category,questionid,yearstart AS year,avg(data_value) AS avarage from servay2020 where gender ='Female' group by questionid,yearstart order by questionid,yearstart , storing results in :: servay_analysis_female_results\n",
      "+--------+----------+----+------------------+\n",
      "|category|questionid|year|           avarage|\n",
      "+--------+----------+----+------------------+\n",
      "|  FEMALE|      Q040|2008|  16.2962962962963|\n",
      "|  FEMALE|      Q040|2010| 16.23518518518518|\n",
      "|  FEMALE|      Q040|2012|15.648148148148145|\n",
      "|  FEMALE|      Q040|2014|15.411111111111113|\n",
      "|  FEMALE|      Q040|2016| 15.39259259259259|\n",
      "|  FEMALE|      Q041|2008| 13.91666666666667|\n",
      "|  FEMALE|      Q041|2010|14.161111111111111|\n",
      "|  FEMALE|      Q041|2012|13.594444444444445|\n",
      "|  FEMALE|      Q041|2014|13.198148148148144|\n",
      "|  FEMALE|      Q041|2016|12.957407407407413|\n",
      "|  FEMALE|      Q060|2008| 12.72962962962963|\n",
      "|  FEMALE|      Q060|2010| 12.38148148148148|\n",
      "|  FEMALE|      Q060|2012|11.264814814814816|\n",
      "|  FEMALE|      Q060|2014|10.725925925925926|\n",
      "|  FEMALE|      Q060|2016|10.996296296296292|\n",
      "+--------+----------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = config()['QUERIES'][ModuleConstants.QUERIES].split('^')\n",
    "tabales = config()['QUERIES'][ModuleConstants.RESULT_TABLES].split(',')\n",
    "SparkUtil.execute_quey_store_results(queries, tabales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkUtil.spark_session().stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
